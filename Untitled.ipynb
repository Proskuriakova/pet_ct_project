{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 255).\n",
       "Contents of stderr:\n",
       "NOTE: Using experimental fast data loading logic. To disable, pass\n",
       "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
       "    https://github.com/tensorflow/tensorboard/issues/4784\n",
       "\n",
       "E0403 15:13:23.456644 140239249700672 program.py:298] TensorBoard could not bind to port 16007, it was already in use\n",
       "ERROR: TensorBoard could not bind to port 16007, it was already in use"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir='experiments/bs2_raw' --port=16007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/__init__.py:126: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n",
      "\"accumulate_grad_batches\": 1\n",
      "\"alpha_weight\":            0.5\n",
      "\"batch_size\":              2\n",
      "\"bucket_size\":             32\n",
      "\"divided_text\":            True\n",
      "\"file_name\":               bs2_raw\n",
      "\"freeze_layers\":           [0, 1, 2, 3]\n",
      "\"gpus\":                    [0, 3]\n",
      "\"image_encoder_model\":     resnet18_3D\n",
      "\"learning_rate\":           1e-05\n",
      "\"loader_workers\":          1\n",
      "\"max_epochs\":              100\n",
      "\"metric_mode\":             min\n",
      "\"min_epochs\":              1\n",
      "\"monitor\":                 val_loss\n",
      "\"name_board\":              bs2_raw\n",
      "\"out_dim\":                 300\n",
      "\"out_name\":                tmp\n",
      "\"path_to_data\":            /data/burenko/datasets/pet-ct\n",
      "\"patience\":                3\n",
      "\"phase\":                   train\n",
      "\"save_top_k\":              2\n",
      "\"seed\":                    3\n",
      "\"temperature\":             0.001\n",
      "\"text_encoder_model\":      sberbank-ai/ruRoberta-large\n",
      "\"use_cosine_similarity\":   True\n",
      "\"val_check_interval\":      2.0\n",
      "\"valid_size\":              0.2\n",
      "LEN 183\n",
      "Some weights of the model checkpoint at sberbank-ai/ruRoberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at sberbank-ai/ruRoberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Text feature extractor: sberbank-ai/ruRoberta-large\n",
      "Image feature extractor: resnet18_3D\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "START TRAINING\n",
      "/usr/lib/python3.6/importlib/__init__.py:126: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n",
      "\"accumulate_grad_batches\": 1\n",
      "\"alpha_weight\":            0.5\n",
      "\"batch_size\":              2\n",
      "\"bucket_size\":             32\n",
      "\"divided_text\":            True\n",
      "\"file_name\":               bs2_raw\n",
      "\"freeze_layers\":           [0, 1, 2, 3]\n",
      "\"gpus\":                    [0, 3]\n",
      "\"image_encoder_model\":     resnet18_3D\n",
      "\"learning_rate\":           1e-05\n",
      "\"loader_workers\":          1\n",
      "\"max_epochs\":              100\n",
      "\"metric_mode\":             min\n",
      "\"min_epochs\":              1\n",
      "\"monitor\":                 val_loss\n",
      "\"name_board\":              bs2_raw\n",
      "\"out_dim\":                 300\n",
      "\"out_name\":                tmp\n",
      "\"path_to_data\":            /data/burenko/datasets/pet-ct\n",
      "\"patience\":                3\n",
      "\"phase\":                   train\n",
      "\"save_top_k\":              2\n",
      "\"seed\":                    3\n",
      "\"temperature\":             0.001\n",
      "\"text_encoder_model\":      sberbank-ai/ruRoberta-large\n",
      "\"use_cosine_similarity\":   True\n",
      "\"val_check_interval\":      2.0\n",
      "\"valid_size\":              0.2\n",
      "LEN 183\n",
      "/usr/lib/python3.6/importlib/__init__.py:126: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n",
      "\"accumulate_grad_batches\": 1\n",
      "\"alpha_weight\":            0.5\n",
      "\"batch_size\":              2\n",
      "\"bucket_size\":             32\n",
      "\"divided_text\":            True\n",
      "\"file_name\":               bs2_raw\n",
      "\"freeze_layers\":           [0, 1, 2, 3]\n",
      "\"gpus\":                    [0, 3]\n",
      "\"image_encoder_model\":     resnet18_3D\n",
      "\"learning_rate\":           1e-05\n",
      "\"loader_workers\":          1\n",
      "\"max_epochs\":              100\n",
      "\"metric_mode\":             min\n",
      "\"min_epochs\":              1\n",
      "\"monitor\":                 val_loss\n",
      "\"name_board\":              bs2_raw\n",
      "\"out_dim\":                 300\n",
      "\"out_name\":                tmp\n",
      "\"path_to_data\":            /data/burenko/datasets/pet-ct\n",
      "\"patience\":                3\n",
      "\"phase\":                   train\n",
      "\"save_top_k\":              2\n",
      "\"seed\":                    3\n",
      "\"temperature\":             0.001\n",
      "\"text_encoder_model\":      sberbank-ai/ruRoberta-large\n",
      "\"use_cosine_similarity\":   True\n",
      "\"val_check_interval\":      2.0\n",
      "\"valid_size\":              0.2\n",
      "LEN 183\n",
      "Some weights of the model checkpoint at sberbank-ai/ruRoberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at sberbank-ai/ruRoberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Text feature extractor: sberbank-ai/ruRoberta-large\n",
      "initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/3\n",
      "Some weights of the model checkpoint at sberbank-ai/ruRoberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at sberbank-ai/ruRoberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Text feature extractor: sberbank-ai/ruRoberta-large\n",
      "Image feature extractor: resnet18_3D\n",
      "START TRAINING\n",
      "initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/3\n",
      "Image feature extractor: resnet18_3D\n",
      "START TRAINING\n",
      "initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 3 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | model_pet | ModelPET   | 392 M \n",
      "1 | _loss     | NTXentLoss | 0     \n",
      "-----------------------------------------\n",
      "341 M     Trainable params\n",
      "50.4 M    Non-trainable params\n",
      "392 M     Total params\n",
      "784.022   Total estimated model params size (MB)\n",
      "Epoch 99: 100%|█| 31/31 [01:27<00:00,  2.84s/it, loss=0.0432, v_num=_raw, train_START TESTING\n",
      "START TESTING\n",
      "Epoch 99: 100%|█| 31/31 [01:31<00:00,  2.97s/it, loss=0.0432, v_num=_raw, train_\n",
      "START TESTING\n"
     ]
    }
   ],
   "source": [
    "!python3 training.py --batch_size 2 --max_epochs 100 --image_encoder_model 'resnet18_3D' --name_board 'bs2_raw' --file_name 'bs2_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/__init__.py:126: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n",
      "\"accumulate_grad_batches\": 1\n",
      "\"alpha_weight\":            0.5\n",
      "\"augmentations\":           True\n",
      "\"batch_size\":              2\n",
      "\"bucket_size\":             32\n",
      "\"divided_text\":            True\n",
      "\"file_name\":               bs2_aug\n",
      "\"freeze_layers\":           [0, 1, 2, 3]\n",
      "\"gpus\":                    [0, 3]\n",
      "\"image_encoder_model\":     resnet18_3D\n",
      "\"learning_rate\":           1e-05\n",
      "\"loader_workers\":          1\n",
      "\"max_epochs\":              100\n",
      "\"metric_mode\":             min\n",
      "\"min_epochs\":              1\n",
      "\"monitor\":                 val_loss\n",
      "\"name_board\":              bs2_aug\n",
      "\"out_dim\":                 300\n",
      "\"out_name\":                tmp\n",
      "\"path_to_data\":            /data/burenko/datasets/pet-ct\n",
      "\"patience\":                3\n",
      "\"phase\":                   train\n",
      "\"save_top_k\":              2\n",
      "\"seed\":                    3\n",
      "\"temperature\":             0.001\n",
      "\"text_encoder_model\":      sberbank-ai/ruRoberta-large\n",
      "\"use_cosine_similarity\":   True\n",
      "\"val_check_interval\":      2.0\n",
      "\"valid_size\":              0.2\n",
      "LEN 183\n",
      "Some weights of the model checkpoint at sberbank-ai/ruRoberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at sberbank-ai/ruRoberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Text feature extractor: sberbank-ai/ruRoberta-large\n",
      "Image feature extractor: resnet18_3D\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "START TRAINING\n",
      "/usr/lib/python3.6/importlib/__init__.py:126: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n",
      "\"accumulate_grad_batches\": 1\n",
      "\"alpha_weight\":            0.5\n",
      "\"augmentations\":           True\n",
      "\"batch_size\":              2\n",
      "\"bucket_size\":             32\n",
      "\"divided_text\":            True\n",
      "\"file_name\":               bs2_aug\n",
      "\"freeze_layers\":           [0, 1, 2, 3]\n",
      "\"gpus\":                    [0, 3]\n",
      "\"image_encoder_model\":     resnet18_3D\n",
      "\"learning_rate\":           1e-05\n",
      "\"loader_workers\":          1\n",
      "\"max_epochs\":              100\n",
      "\"metric_mode\":             min\n",
      "\"min_epochs\":              1\n",
      "\"monitor\":                 val_loss\n",
      "\"name_board\":              bs2_aug\n",
      "\"out_dim\":                 300\n",
      "\"out_name\":                tmp\n",
      "\"path_to_data\":            /data/burenko/datasets/pet-ct\n",
      "\"patience\":                3\n",
      "\"phase\":                   train\n",
      "\"save_top_k\":              2\n",
      "\"seed\":                    3\n",
      "\"temperature\":             0.001\n",
      "\"text_encoder_model\":      sberbank-ai/ruRoberta-large\n",
      "\"use_cosine_similarity\":   True\n",
      "\"val_check_interval\":      2.0\n",
      "\"valid_size\":              0.2\n",
      "LEN 183\n",
      "/usr/lib/python3.6/importlib/__init__.py:126: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n",
      "initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/3\n",
      "\"accumulate_grad_batches\": 1\n",
      "\"alpha_weight\":            0.5\n",
      "\"augmentations\":           True\n",
      "\"batch_size\":              2\n",
      "\"bucket_size\":             32\n",
      "\"divided_text\":            True\n",
      "\"file_name\":               bs2_aug\n",
      "\"freeze_layers\":           [0, 1, 2, 3]\n",
      "\"gpus\":                    [0, 3]\n",
      "\"image_encoder_model\":     resnet18_3D\n",
      "\"learning_rate\":           1e-05\n",
      "\"loader_workers\":          1\n",
      "\"max_epochs\":              100\n",
      "\"metric_mode\":             min\n",
      "\"min_epochs\":              1\n",
      "\"monitor\":                 val_loss\n",
      "\"name_board\":              bs2_aug\n",
      "\"out_dim\":                 300\n",
      "\"out_name\":                tmp\n",
      "\"path_to_data\":            /data/burenko/datasets/pet-ct\n",
      "\"patience\":                3\n",
      "\"phase\":                   train\n",
      "\"save_top_k\":              2\n",
      "\"seed\":                    3\n",
      "\"temperature\":             0.001\n",
      "\"text_encoder_model\":      sberbank-ai/ruRoberta-large\n",
      "\"use_cosine_similarity\":   True\n",
      "\"val_check_interval\":      2.0\n",
      "\"valid_size\":              0.2\n",
      "LEN 183\n",
      "Some weights of the model checkpoint at sberbank-ai/ruRoberta-large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at sberbank-ai/ruRoberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Text feature extractor: sberbank-ai/ruRoberta-large\n",
      "Some weights of the model checkpoint at sberbank-ai/ruRoberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at sberbank-ai/ruRoberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Text feature extractor: sberbank-ai/ruRoberta-large\n",
      "Image feature extractor: resnet18_3D\n",
      "START TRAINING\n",
      "initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/3\n",
      "Image feature extractor: resnet18_3D\n",
      "START TRAINING\n",
      "initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 3 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | model_pet | ModelPET   | 392 M \n",
      "1 | _loss     | NTXentLoss | 0     \n",
      "-----------------------------------------\n",
      "341 M     Trainable params\n",
      "50.4 M    Non-trainable params\n",
      "392 M     Total params\n",
      "784.022   Total estimated model params size (MB)\n",
      "Epoch 99: 100%|█| 31/31 [02:21<00:00,  4.56s/it, loss=0.285, v_num=_aug, train_lSTART TESTING\n",
      "START TESTING\n",
      "Epoch 99: 100%|█| 31/31 [02:25<00:00,  4.69s/it, loss=0.285, v_num=_aug, train_l\n",
      "START TESTING\n"
     ]
    }
   ],
   "source": [
    "!python3 training.py --batch_size 2 --max_epochs 100 --image_encoder_model 'resnet18_3D' --name_board 'bs2_aug' --file_name 'bs2_aug' --augmentations True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/__init__.py:126: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n",
      "\"accumulate_grad_batches\": 1\n",
      "\"alpha_weight\":            0.5\n",
      "\"batch_size\":              2\n",
      "\"bucket_size\":             32\n",
      "\"divided_text\":            True\n",
      "\"freeze_layers\":           [0, 1, 2, 3]\n",
      "\"gpus\":                    [0, 3]\n",
      "\"image_encoder_model\":     resnet18_3D\n",
      "\"learning_rate\":           1e-05\n",
      "\"loader_workers\":          6\n",
      "\"max_epochs\":              20\n",
      "\"metric_mode\":             min\n",
      "\"min_epochs\":              1\n",
      "\"monitor\":                 val_loss\n",
      "\"name_board\":              tmp\n",
      "\"out_dim\":                 300\n",
      "\"path_to_data\":            /data/burenko/datasets/pet-ct\n",
      "\"patience\":                3\n",
      "\"phase\":                   test\n",
      "\"save_top_k\":              2\n",
      "\"seed\":                    3\n",
      "\"temperature\":             1e-05\n",
      "\"text_encoder_model\":      DeepPavlov/rubert-base-cased-sentence\n",
      "\"use_cosine_similarity\":   True\n",
      "\"val_check_interval\":      2.0\n",
      "\"valid_size\":              0.2\n",
      "LEN 183\n",
      "Text feature extractor: DeepPavlov/rubert-base-cased-sentence\n",
      "Image feature extractor: resnet18_3D\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "START TESTING\n",
      "\"accumulate_grad_batches\": 1\n",
      "\"alpha_weight\":            0.5\n",
      "\"batch_size\":              2\n",
      "\"bucket_size\":             32\n",
      "\"divided_text\":            True\n",
      "\"freeze_layers\":           [0, 1, 2, 3]\n",
      "\"gpus\":                    [0, 3]\n",
      "\"image_encoder_model\":     resnet18_3D\n",
      "\"learning_rate\":           1e-05\n",
      "\"loader_workers\":          6\n",
      "\"max_epochs\":              5\n",
      "\"metric_mode\":             min\n",
      "\"min_epochs\":              1\n",
      "\"monitor\":                 val_loss\n",
      "\"name_board\":              bs_2_petct_11\n",
      "\"out_dim\":                 300\n",
      "\"path_to_data\":            /data/burenko/datasets/pet-ct\n",
      "\"patience\":                3\n",
      "\"phase\":                   train\n",
      "\"save_top_k\":              2\n",
      "\"seed\":                    3\n",
      "\"temperature\":             1e-05\n",
      "\"text_encoder_model\":      DeepPavlov/rubert-base-cased-sentence\n",
      "\"use_cosine_similarity\":   True\n",
      "\"val_check_interval\":      2.0\n",
      "\"valid_size\":              0.2\n",
      "LEN 183\n",
      "Text feature extractor: DeepPavlov/rubert-base-cased-sentence\n",
      "Image feature extractor: resnet18_3D\n",
      "/usr/lib/python3.6/importlib/__init__.py:126: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n",
      "\"accumulate_grad_batches\": 1\n",
      "\"alpha_weight\":            0.5\n",
      "\"batch_size\":              2\n",
      "\"bucket_size\":             32\n",
      "\"divided_text\":            True\n",
      "\"freeze_layers\":           [0, 1, 2, 3]\n",
      "\"gpus\":                    [0, 3]\n",
      "\"image_encoder_model\":     resnet18_3D\n",
      "\"learning_rate\":           1e-05\n",
      "\"loader_workers\":          6\n",
      "\"max_epochs\":              20\n",
      "\"metric_mode\":             min\n",
      "\"min_epochs\":              1\n",
      "\"monitor\":                 val_loss\n",
      "\"name_board\":              tmp\n",
      "\"out_dim\":                 300\n",
      "\"path_to_data\":            /data/burenko/datasets/pet-ct\n",
      "\"patience\":                3\n",
      "\"phase\":                   test\n",
      "\"save_top_k\":              2\n",
      "\"seed\":                    3\n",
      "\"temperature\":             1e-05\n",
      "\"text_encoder_model\":      DeepPavlov/rubert-base-cased-sentence\n",
      "\"use_cosine_similarity\":   True\n",
      "\"val_check_interval\":      2.0\n",
      "\"valid_size\":              0.2\n",
      "LEN 183\n",
      "Text feature extractor: DeepPavlov/rubert-base-cased-sentence\n",
      "/usr/lib/python3.6/importlib/__init__.py:126: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n",
      "\"accumulate_grad_batches\": 1\n",
      "\"alpha_weight\":            0.5\n",
      "\"batch_size\":              2\n",
      "\"bucket_size\":             32\n",
      "\"divided_text\":            True\n",
      "\"freeze_layers\":           [0, 1, 2, 3]\n",
      "\"gpus\":                    [0, 3]\n",
      "\"image_encoder_model\":     resnet18_3D\n",
      "\"learning_rate\":           1e-05\n",
      "\"loader_workers\":          6\n",
      "\"max_epochs\":              20\n",
      "\"metric_mode\":             min\n",
      "\"min_epochs\":              1\n",
      "\"monitor\":                 val_loss\n",
      "\"name_board\":              tmp\n",
      "\"out_dim\":                 300\n",
      "\"path_to_data\":            /data/burenko/datasets/pet-ct\n",
      "\"patience\":                3\n",
      "\"phase\":                   test\n",
      "\"save_top_k\":              2\n",
      "\"seed\":                    3\n",
      "\"temperature\":             1e-05\n",
      "\"text_encoder_model\":      DeepPavlov/rubert-base-cased-sentence\n",
      "\"use_cosine_similarity\":   True\n",
      "\"val_check_interval\":      2.0\n",
      "\"valid_size\":              0.2\n",
      "LEN 183\n",
      "initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/3\n",
      "Text feature extractor: DeepPavlov/rubert-base-cased-sentence\n",
      "Image feature extractor: resnet18_3D\n",
      "START TESTING\n",
      "\"accumulate_grad_batches\": 1\n",
      "\"alpha_weight\":            0.5\n",
      "\"batch_size\":              2\n",
      "\"bucket_size\":             32\n",
      "\"divided_text\":            True\n",
      "\"freeze_layers\":           [0, 1, 2, 3]\n",
      "\"gpus\":                    [0, 3]\n",
      "\"image_encoder_model\":     resnet18_3D\n",
      "\"learning_rate\":           1e-05\n",
      "\"loader_workers\":          6\n",
      "\"max_epochs\":              5\n",
      "\"metric_mode\":             min\n",
      "\"min_epochs\":              1\n",
      "\"monitor\":                 val_loss\n",
      "\"name_board\":              bs_2_petct_11\n",
      "\"out_dim\":                 300\n",
      "\"path_to_data\":            /data/burenko/datasets/pet-ct\n",
      "\"patience\":                3\n",
      "\"phase\":                   train\n",
      "\"save_top_k\":              2\n",
      "\"seed\":                    3\n",
      "\"temperature\":             1e-05\n",
      "\"text_encoder_model\":      DeepPavlov/rubert-base-cased-sentence\n",
      "\"use_cosine_similarity\":   True\n",
      "\"val_check_interval\":      2.0\n",
      "\"valid_size\":              0.2\n",
      "LEN 183\n",
      "Text feature extractor: DeepPavlov/rubert-base-cased-sentence\n",
      "Image feature extractor: resnet18_3D\n",
      "START TESTING\n",
      "\"accumulate_grad_batches\": 1\n",
      "\"alpha_weight\":            0.5\n",
      "\"batch_size\":              2\n",
      "\"bucket_size\":             32\n",
      "\"divided_text\":            True\n",
      "\"freeze_layers\":           [0, 1, 2, 3]\n",
      "\"gpus\":                    [0, 3]\n",
      "\"image_encoder_model\":     resnet18_3D\n",
      "\"learning_rate\":           1e-05\n",
      "\"loader_workers\":          6\n",
      "\"max_epochs\":              5\n",
      "\"metric_mode\":             min\n",
      "\"min_epochs\":              1\n",
      "\"monitor\":                 val_loss\n",
      "\"name_board\":              bs_2_petct_11\n",
      "\"out_dim\":                 300\n",
      "\"path_to_data\":            /data/burenko/datasets/pet-ct\n",
      "\"patience\":                3\n",
      "\"phase\":                   train\n",
      "\"save_top_k\":              2\n",
      "\"seed\":                    3\n",
      "\"temperature\":             1e-05\n",
      "\"text_encoder_model\":      DeepPavlov/rubert-base-cased-sentence\n",
      "\"use_cosine_similarity\":   True\n",
      "\"val_check_interval\":      2.0\n",
      "\"valid_size\":              0.2\n",
      "LEN 183\n",
      "Text feature extractor: DeepPavlov/rubert-base-cased-sentence\n",
      "Image feature extractor: resnet18_3D\n",
      "initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/3\n",
      "Image feature extractor: resnet18_3D\n",
      "initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 3 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Testing:  90%|██████████████████████████████▋   | 28/31 [00:17<00:01,  2.11it/s]ALL 61\n",
      "zero element 300\n",
      "Testing:  97%|████████████████████████████████▉ | 30/31 [00:18<00:00,  2.07it/s]ALL 61\n",
      "zero element 300\n",
      "Testing: 100%|██████████████████████████████████| 31/31 [00:18<00:00,  2.29it/s]ALL 61\n",
      "zero element 300\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': nan, 'test_loss_epoch': nan}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████████████████████████████| 31/31 [00:18<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 training.py --batch_size 2 --loader_workers 6 --image_encoder_model 'resnet18_3D' --phase 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open('results/image_embeddings_tmp.npy', 'rb') as f:\n",
    "    texts_embeds = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_embeds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open('images_embeddings_bs3.npy', 'rb') as f:\n",
    "    images_embeds = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0339660645"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.39660645e-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_img = []\n",
    "for i in range(images_embeds_t.shape[0]):\n",
    "    sim_i = []\n",
    "    for j in range(images_embeds_t.shape[0]):\n",
    "        sim_i.append(cosine_similarity(images_embeds_t[i].unsqueeze(0), images_embeds_t[j].unsqueeze(0)).numpy()[0])\n",
    "    sims_img.append(sim_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_img = [sorted(sims_img[i], reverse = True)[1:6] for i in range(len(sims_img))]\n",
    "ind_top5_img = []\n",
    "for i in range(len(top_5_img)):\n",
    "    ind_i = []\n",
    "    for j in range(len(sims_img[i])):\n",
    "        if sims_img[i][j] in top_5_img[i]:\n",
    "            ind_i.append(j)\n",
    "    ind_top5_img.append(ind_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[26, 46, 53, 58, 60],\n",
       " [16, 20, 27, 29, 43],\n",
       " [9, 15, 17, 19, 24],\n",
       " [2, 9, 13, 22, 37],\n",
       " [10, 31, 42, 48, 49]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_top5_img[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_txt = []\n",
    "for i in range(texts_embeds_t.shape[0]):\n",
    "    sim_i = []\n",
    "    for j in range(texts_embeds_t.shape[0]):\n",
    "        sim_i.append(cosine_similarity(texts_embeds_t[i].unsqueeze(0), texts_embeds_t[j].unsqueeze(0)).numpy()[0])\n",
    "    sims_txt.append(sim_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_txt = [sorted(sims_txt[i], reverse = True)[1:6] for i in range(len(sims_txt))]\n",
    "ind_top5_txt = []\n",
    "for i in range(len(top_5_txt)):\n",
    "    ind_i = []\n",
    "    for j in range(len(sims_txt[i])):\n",
    "        if sims_txt[i][j] in top_5_txt[i]:\n",
    "            ind_i.append(j)\n",
    "    ind_top5_txt.append(ind_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 22, 24, 26, 30],\n",
       " [4, 16, 18, 23, 50],\n",
       " [4, 32, 37, 50, 56],\n",
       " [11, 22, 32, 34, 45],\n",
       " [10, 21, 23, 28, 50]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_top5_txt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_all = []\n",
    "for i in range(images_embeds_t.shape[0]):\n",
    "    sim_i = []\n",
    "    for j in range(texts_embeds_t.shape[0]):\n",
    "        sim_i.append(cosine_similarity(images_embeds_t[i].unsqueeze(0), texts_embeds_t[j].unsqueeze(0)).numpy()[0])\n",
    "    sims_all.append(sim_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_5 = [sorted(sims_all[i], reverse = True)[:5] for i in range(len(sims_all))]\n",
    "ind_top5 = []\n",
    "for i in range(len(top_5)):\n",
    "    ind_i = []\n",
    "    for j in range(len(sims_all[i])):\n",
    "        if sims_all[i][j] in top_5[i]:\n",
    "            ind_i.append(j)\n",
    "    ind_top5.append(ind_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.026543573, -0.028643612, -0.029380657, -0.029541535, -0.029926134],\n",
       " [-0.016220812, -0.016299615, -0.016781945, -0.017157972, -0.021519426],\n",
       " [-0.027904559, -0.02927977, -0.030047506, -0.0304393, -0.030554557],\n",
       " [-0.03405707, -0.034326747, -0.03445782, -0.03487183, -0.034909394],\n",
       " [-0.017335624, -0.02107842, -0.02234599, -0.022888958, -0.023271568],\n",
       " [-0.028386125, -0.030034548, -0.030734431, -0.031018743, -0.031500313],\n",
       " [-0.02641942, -0.028294716, -0.029012801, -0.02901769, -0.029799111],\n",
       " [-0.020239621, -0.02174632, -0.022202184, -0.022309782, -0.023968082],\n",
       " [-0.01970102, -0.020040212, -0.021465449, -0.021810614, -0.022142192],\n",
       " [-0.030775279, -0.031056605, -0.031288624, -0.031467102, -0.03211446],\n",
       " [-0.016073296, -0.017690122, -0.018930117, -0.019024579, -0.019437296],\n",
       " [-0.02240991, -0.02364739, -0.023711365, -0.024034958, -0.024697833],\n",
       " [-0.026531737, -0.029181225, -0.029320471, -0.029352358, -0.029606],\n",
       " [-0.030308206, -0.031525753, -0.03153657, -0.032321047, -0.032481015],\n",
       " [-0.011941346, -0.012239384, -0.013621976, -0.014548301, -0.015139744],\n",
       " [-0.024098901, -0.026422394, -0.027424343, -0.02793081, -0.028662767],\n",
       " [-0.0126767615, -0.013426761, -0.013584293, -0.013590384, -0.01801739],\n",
       " [-0.027212009, -0.02771416, -0.029269759, -0.03048248, -0.031697657],\n",
       " [-0.019642001, -0.019740555, -0.019780314, -0.020107348, -0.020924352],\n",
       " [-0.026222978, -0.028241755, -0.02844713, -0.028485822, -0.028583426],\n",
       " [-0.015556117, -0.015823556, -0.016081491, -0.016838616, -0.020985173],\n",
       " [-0.016008269, -0.017527185, -0.017635008, -0.019391686, -0.019679807],\n",
       " [-0.02874133, -0.0293364, -0.029798312, -0.030754982, -0.03101097],\n",
       " [-0.02512299, -0.026509285, -0.0285118, -0.028601157, -0.028723963],\n",
       " [-0.0276653, -0.029482158, -0.029717637, -0.029979441, -0.030820888],\n",
       " [-0.019609528, -0.022152686, -0.022310002, -0.02294291, -0.02413032],\n",
       " [-0.025304204, -0.029269498, -0.029374164, -0.030060662, -0.030068649],\n",
       " [-0.014767, -0.015105243, -0.01566381, -0.015698474, -0.019654056],\n",
       " [-0.027208637, -0.027983513, -0.029274903, -0.029861432, -0.030224638],\n",
       " [-0.015279513, -0.015795028, -0.016519632, -0.016801193, -0.020724358],\n",
       " [-0.024575518, -0.025293574, -0.025512928, -0.026946414, -0.027158786],\n",
       " [-0.018754607, -0.022036385, -0.023303963, -0.023522658, -0.024492834],\n",
       " [-0.02706964, -0.027630238, -0.029417085, -0.029501164, -0.02966092],\n",
       " [-0.0178873, -0.01897358, -0.019193178, -0.02048536, -0.020553185],\n",
       " [-0.025591232, -0.027635, -0.029188335, -0.029289752, -0.03029009],\n",
       " [-0.027783314, -0.028170265, -0.028170874, -0.028360179, -0.029199073],\n",
       " [-0.022605648, -0.024309047, -0.024767533, -0.026589869, -0.027759401],\n",
       " [-0.02912535, -0.029290352, -0.03085959, -0.03093452, -0.031085895],\n",
       " [-0.02364512, -0.023674432, -0.02375851, -0.024721166, -0.025602093],\n",
       " [-0.02491889, -0.024978938, -0.025900127, -0.026016518, -0.026669696],\n",
       " [-0.027711755, -0.02814123, -0.028379852, -0.028460618, -0.02975764],\n",
       " [-0.027996972, -0.02859376, -0.028631201, -0.029417837, -0.030410454],\n",
       " [-0.019325137, -0.021657195, -0.023029435, -0.023137495, -0.02346726],\n",
       " [-0.0158274, -0.01713684, -0.01757431, -0.017767716, -0.022050967],\n",
       " [-0.006448443, -0.0073697213, -0.0077983667, -0.009095628, -0.009247264],\n",
       " [-0.023075432, -0.023408467, -0.023708863, -0.023822378, -0.025673775],\n",
       " [-0.029040417, -0.029869497, -0.030560117, -0.030639663, -0.031697996],\n",
       " [-0.028389486, -0.028662803, -0.029673373, -0.030581841, -0.030799761],\n",
       " [-0.018911144, -0.019642545, -0.019980863, -0.020038044, -0.020881044],\n",
       " [-0.019563358, -0.021405466, -0.024960198, -0.024980783, -0.025924902],\n",
       " [-0.025606383, -0.026235221, -0.026956316, -0.027122034, -0.027762305],\n",
       " [-0.025927134, -0.029660372, -0.030416476, -0.030470615, -0.03140412],\n",
       " [-0.028362751, -0.030289559, -0.030411268, -0.030583203, -0.030638624],\n",
       " [-0.028778415, -0.030160137, -0.03075345, -0.031136412, -0.031912837],\n",
       " [-0.026773527, -0.027711587, -0.028797459, -0.028983427, -0.029082628],\n",
       " [-0.032091837, -0.032950364, -0.033347484, -0.033776227, -0.03387367],\n",
       " [-0.023713935, -0.023787923, -0.024219507, -0.025621679, -0.025893489],\n",
       " [-0.025720576, -0.025816824, -0.026159702, -0.026389299, -0.02683188],\n",
       " [-0.02901615, -0.029502124, -0.029769814, -0.030612756, -0.031154592],\n",
       " [-0.0263396, -0.027392244, -0.027502298, -0.027567798, -0.028792692],\n",
       " [-0.028186599, -0.028438808, -0.030832725, -0.031006174, -0.031246347]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14, 18, 30, 42, 51],\n",
       " [1, 16, 20, 27, 43],\n",
       " [25, 30, 42, 47, 51],\n",
       " [14, 25, 30, 51, 55],\n",
       " [18, 30, 42, 51, 52],\n",
       " [30, 42, 44, 47, 51],\n",
       " [18, 25, 30, 42, 47],\n",
       " [25, 30, 42, 44, 47],\n",
       " [18, 30, 44, 47, 51],\n",
       " [18, 25, 30, 42, 48],\n",
       " [18, 30, 42, 47, 51],\n",
       " [18, 30, 44, 47, 51],\n",
       " [14, 42, 44, 47, 51],\n",
       " [14, 25, 30, 42, 48],\n",
       " [18, 30, 44, 47, 51],\n",
       " [25, 30, 42, 44, 47],\n",
       " [16, 20, 27, 29, 43],\n",
       " [14, 18, 25, 30, 48],\n",
       " [4, 10, 18, 42, 51],\n",
       " [14, 18, 25, 30, 51],\n",
       " [1, 16, 20, 27, 43],\n",
       " [4, 10, 18, 42, 51],\n",
       " [14, 25, 30, 42, 51],\n",
       " [4, 18, 30, 31, 51],\n",
       " [14, 25, 30, 42, 47],\n",
       " [18, 25, 30, 42, 44],\n",
       " [14, 18, 42, 44, 51],\n",
       " [16, 20, 27, 29, 43],\n",
       " [18, 31, 42, 47, 51],\n",
       " [1, 16, 20, 27, 43],\n",
       " [30, 42, 44, 47, 51],\n",
       " [4, 18, 30, 42, 51],\n",
       " [18, 30, 44, 47, 51],\n",
       " [10, 18, 30, 42, 51],\n",
       " [18, 25, 30, 44, 47],\n",
       " [18, 30, 44, 47, 51],\n",
       " [18, 25, 30, 44, 47],\n",
       " [14, 25, 30, 42, 48],\n",
       " [18, 30, 42, 47, 51],\n",
       " [18, 30, 42, 47, 51],\n",
       " [18, 30, 47, 51, 57],\n",
       " [18, 30, 44, 47, 51],\n",
       " [18, 30, 42, 51, 52],\n",
       " [1, 16, 20, 27, 43],\n",
       " [10, 30, 42, 47, 51],\n",
       " [4, 39, 42, 49, 51],\n",
       " [18, 25, 42, 51, 55],\n",
       " [18, 42, 44, 47, 51],\n",
       " [4, 18, 30, 42, 51],\n",
       " [4, 18, 30, 42, 51],\n",
       " [18, 30, 42, 47, 51],\n",
       " [14, 18, 42, 47, 51],\n",
       " [18, 30, 42, 47, 51],\n",
       " [14, 18, 30, 51, 57],\n",
       " [18, 30, 42, 47, 51],\n",
       " [4, 18, 20, 42, 51],\n",
       " [18, 25, 30, 42, 44],\n",
       " [18, 30, 44, 47, 51],\n",
       " [30, 42, 44, 47, 51],\n",
       " [18, 30, 42, 47, 51],\n",
       " [14, 18, 30, 43, 51]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.028727762"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(images_embeds_t[1].unsqueeze(0), texts_embeds_t[45].unsqueeze(0)).numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0348])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(images_embeds_t[0].unsqueeze(0), texts_embeds_t[49].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_embeds_t[0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.Tensor(images_embeds[0]).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import NTXentLoss\n",
    "\n",
    "n = images_embeds.shape[0]\n",
    "loss_ = NTXentLoss(batch_size = n, temperature = 1e-5, use_cosine_similarity = True, alpha_weight = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(-0., dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_(torch.Tensor(images_embeds).unsqueeze(0), torch.Tensor(images_embeds[1]).unsqueeze(0)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_embeds_t = [torch.Tensor(images_embeds[i]).unsqueeze(0) for i in range(len(images_embeds))]\n",
    "images_embeds_t = torch.vstack(images_embeds_t)\n",
    "\n",
    "texts_embeds_t = [torch.Tensor(texts_embeds[i]).unsqueeze(0) for i in range(len(texts_embeds))]\n",
    "texts_embeds_t = torch.vstack(texts_embeds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(389.6702)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_(images_embeds_t, texts_embeds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = images_embeds_t\n",
    "hidden2 = texts_embeds_t\n",
    "batch_size = hidden1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1_large = hidden1\n",
    "hidden2_large = hidden2\n",
    "temperature = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "labels = F.one_hot(torch.arange(start=0, end=batch_size, dtype=torch.int64), num_classes=batch_size).float()\n",
    "labels = labels.type_as(hidden1)\n",
    "masks = F.one_hot(torch.arange(start=0, end=batch_size, dtype=torch.int64), num_classes=batch_size)\n",
    "\n",
    "\"\"\"\n",
    "Different from Image-Image contrastive learning\n",
    "In the case of Image-Text contrastive learning we do not compute the similarity function between the Image-Image and Text-Text pairs  \n",
    "\"\"\"\n",
    "# logits_aa = torch.matmul(hidden1, torch.transpose(hidden1_large,0, 1)) / temperature\n",
    "# logits_aa = logits_aa - masks * LARGE_NUM\n",
    "# logits_bb = torch.matmul(hidden2,  torch.transpose(hidden2_large,0, 1)) / temperature\n",
    "# logits_bb = logits_bb - masks * LARGE_NUM\n",
    "logits_ab = torch.matmul(hidden1, torch.transpose(hidden2_large,0, 1)) / temperature\n",
    "logits_ba = torch.matmul(hidden2, torch.transpose(hidden1_large,0, 1)) / temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprobs_ab = (torch.nn.functional.log_softmax(logits_ab, dim = 1)).numpy()\n",
    "logprobs_ba = torch.nn.functional.log_softmax(logits_ba, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = [sorted(logprobs_ab[i], reverse = True)[:5] for i in range(len(logprobs_ab))]\n",
    "ind_top5 = []\n",
    "for i in range(len(top_5)):\n",
    "    ind_i = []\n",
    "    for j in range(len(logprobs_ab[i])):\n",
    "        if logprobs_ab[i][j] in top_5[i]:\n",
    "            ind_i.append(j)\n",
    "    ind_top5.append(ind_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Proskuriakova/pet_ct_project_pl.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#git remote set-url origin https://Proskuriakova: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@github.com/Proskuriakova/pet_ct_project_pl.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "path_to_data = '/data/burenko/datasets/pet-ct'\n",
    "names = []\n",
    "for dir_content in listdir(path_to_data):\n",
    "    if dir_content.split('.')[-1] == 'npy':\n",
    "        names.append(dir_content.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import PETDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PETDataset(path_to_data, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_img = data[0]['image'][..., :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 156, 156, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import generate_model\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'block_inplanes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2a1a85fc929b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnum_ftrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mres_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/proskuryakova/pet_ct_pl/resnet.py\u001b[0m in \u001b[0;36mgenerate_model\u001b[0;34m(model_depth, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasicBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_inplanes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasicBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_inplanes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasicBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_inplanes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'block_inplanes'"
     ]
    }
   ],
   "source": [
    "model = generate_model(model_depth=18)\n",
    "num_ftrs = model.fc.in_features\n",
    "res_features = nn.Sequential(*list(model.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "model_pt = torchvision.models.video.r3d_18(pretrained = False)\n",
    "num_ftrs_pt = model_pt.fc.in_features\n",
    "res_features_pt = nn.Sequential(*list(model_pt.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pt = res_features_pt(tmp_img.unsqueeze(0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 156, 156, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_img.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(39/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn1 torch.Size([1, 64, 78, 39, 3])\n",
      "bn2 torch.Size([1, 64, 78, 39, 3])\n",
      "bn3 torch.Size([1, 256, 78, 39, 3])\n",
      "bn1 torch.Size([1, 64, 78, 39, 3])\n",
      "bn2 torch.Size([1, 64, 78, 39, 3])\n",
      "bn3 torch.Size([1, 256, 78, 39, 3])\n",
      "bn1 torch.Size([1, 64, 78, 39, 3])\n",
      "bn2 torch.Size([1, 64, 78, 39, 3])\n",
      "bn3 torch.Size([1, 256, 78, 39, 3])\n",
      "bn1 torch.Size([1, 128, 78, 39, 3])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 128, 39, 20, 2])\n",
      "bn2 torch.Size([1, 128, 39, 20, 2])\n",
      "bn3 torch.Size([1, 512, 39, 20, 2])\n",
      "bn1 torch.Size([1, 256, 39, 20, 2])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 256, 20, 10, 1])\n",
      "bn2 torch.Size([1, 256, 20, 10, 1])\n",
      "bn3 torch.Size([1, 1024, 20, 10, 1])\n",
      "bn1 torch.Size([1, 512, 20, 10, 1])\n",
      "bn2 torch.Size([1, 512, 10, 5, 1])\n",
      "bn3 torch.Size([1, 2048, 10, 5, 1])\n",
      "bn1 torch.Size([1, 512, 10, 5, 1])\n",
      "bn2 torch.Size([1, 512, 10, 5, 1])\n",
      "bn3 torch.Size([1, 2048, 10, 5, 1])\n",
      "bn1 torch.Size([1, 512, 10, 5, 1])\n",
      "bn2 torch.Size([1, 512, 10, 5, 1])\n",
      "bn3 torch.Size([1, 2048, 10, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "h = res_features(tmp_img.unsqueeze(0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic1 torch.Size([1, 64, 78, 39, 3])\n",
      "basic2 torch.Size([1, 64, 78, 39, 3])\n",
      "basic1 torch.Size([1, 64, 78, 39, 3])\n",
      "basic2 torch.Size([1, 64, 78, 39, 3])\n",
      "basic1 torch.Size([1, 128, 39, 20, 2])\n",
      "basic2 torch.Size([1, 128, 39, 20, 2])\n",
      "basic1 torch.Size([1, 128, 39, 20, 2])\n",
      "basic2 torch.Size([1, 128, 39, 20, 2])\n",
      "basic1 torch.Size([1, 256, 20, 10, 1])\n",
      "basic2 torch.Size([1, 256, 20, 10, 1])\n",
      "basic1 torch.Size([1, 256, 20, 10, 1])\n",
      "basic2 torch.Size([1, 256, 20, 10, 1])\n",
      "basic1 torch.Size([1, 512, 10, 5, 1])\n",
      "basic2 torch.Size([1, 512, 10, 5, 1])\n",
      "basic1 torch.Size([1, 512, 10, 5, 1])\n",
      "basic2 torch.Size([1, 512, 10, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "h = res_features(tmp_img.unsqueeze(0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6609, 0.7288, 0.6048, 0.6723, 0.7622, 0.7937, 0.8822, 0.7717, 0.8515,\n",
       "        0.6970], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pt[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7809, 0.8636, 0.8472, 0.7782, 0.7231, 0.7052, 0.7394, 0.7016, 0.7401,\n",
       "        0.7761], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=1,\n",
    "                     bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_norm(x):\n",
    "    return nn.LayerNorm(x.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3d = conv3x3x3(3, 64, 2)\n",
    "bn1 = nn.LayerNorm([])\n",
    "bn2 = nn.BatchNorm3d(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3d.out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 78, 78, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = conv3d(tmp_img.unsqueeze(0))\n",
    "out1.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = layer_norm(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LayerNorm' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-06386c8b30ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/proskuryakova/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LayerNorm' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 156, 156, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn2(out1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = conv1(x)\n",
    "out = bn1(out)\n",
    "out = relu(out)\n",
    "\n",
    "out = conv2(out)\n",
    "out = bn2(out)\n",
    "out = relu(out)\n",
    "\n",
    "out = conv3(out)\n",
    "out = bn3(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
